{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"cuarto\"></a>\n",
    "## 4. Transfer Learning\n",
    "En esta sección se trabajará con el dataset trabajado anteriormente, CIFAR [3], pero en su versión mas fina en el cual se presentan 100 tipos distintos de categorías a clasificar la imagen, no 10 como se usó en las actividades anteriores. La estructura es la misma, son 60000 imágenes RGB de 32 $\\times$ 32 píxeles separados en 50 mil de entrenamiento y 10 mil de pruebas.  \n",
    "Aquí se experimentará con el concepto de *transfer learning* el cual consta en transferir conocimiento de un dominio fuente (*source domain*) a un dominio objetivo (*target domain*). En redes neuronales existen muchas representaciones de esto, en común consta en pre inicializar los pesos de la red de alguna manera que no sea con distribuciones de manera aleatoria. También está lo que es utilizar una representación generada a través de otra red entrenada con muchos datos, esto es tomar la red y \"*congelar*\" sus primeras capas para tomar esta representación y no entrenar esos pesos.  \n",
    "\n",
    "Para cargar los datos utilice el siguiente comando:\n",
    "```python\n",
    "from keras.datasets import cifar100\n",
    "(x_train, y_train), (x_test, y_test) = cifar100.load_data(label_mode='fine')\n",
    "```\n",
    "\n",
    "Normalice y transforme las etiquetas en *one hot* vector.\n",
    "```python\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes=100)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes=100)\n",
    "x_train = x_train/255.0\n",
    "x_test = x_test/255.0\n",
    "```\n",
    "\n",
    "> a) Entrene una red neuronal convolucional como se presenta en el código a continuación durante 15 *epochs*, realizando un gráfico de evolución de la función de pérdida y de la exactitud del algoritmo (*accuracy*) sobre ambos conjuntos, entrenamiento y pruebas. Comente sobre el tiempo de ejecución de este entrenamiento. Reporte el *accuracy* del modelo final sobre el conjunto de pruebas.\n",
    "```python\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Conv2D,MaxPooling2D,Flatten,Dropout\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), padding='same',input_shape=x_train.shape[1:],activation='relu'))\n",
    "model.add(Conv2D(32, (3, 3),padding='same',activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Conv2D(64, (3, 3),padding='same',activation='relu'))\n",
    "model.add(Conv2D(64, (3, 3),padding='same',activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1024,activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "...#add clasification layer\n",
    "model.summary()\n",
    "```\n",
    "<div class=\"alert alert-block alert-info\">Se utiliza una tasa de aprendizaje pequeña ya que es lo recomendable en *transfer learning*.</div>\n",
    "```python\n",
    "#train it\n",
    "optimizer_ = SGD(lr=0.01,momentum=0.9)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optimizer_, metrics=['accuracy'])\n",
    "model.fit(x_train, y_train, batch_size=128,epochs=15,verbose=1, validation_data=(x_test,y_test))\n",
    "```\n",
    "\n",
    "> b) Debido al comportamiento de las curvas de entrenamiento, claramente se ve que se necesita un regularizador. Experimente utilizando Dropout con una tasa de 0.25 en las tandas convolucionales, elija donde situarlo, luego de la primera convolución, después de la segunda, solamente después del *pooling*, en todas o alguna forma que le parezca conveniente, de argumentos de ello. La idea es que se forme una idea de dónde conviene colocar el regularizador y porqué.\n",
    "\n",
    "> c) Como pre entrenamiento de la misma red definida en a) de una manera no supervisada se trabajará con un autoencoder convolucional, el cual no necesita etiqueta de los datos por lo que se puede aprovechar de transferir lo aprendido con datos sin conocer si pertenecen a la misma categoría o no. Comente y analice si esto mejora lo visto en a). *Utilice todas las imágenes no etiquetadas que desee*.\n",
    "```python\n",
    "from keras.layers import Input\n",
    "from keras.models import Model\n",
    "###BUILD AUTOENCODER1\n",
    "input_img = Input(shape=x_train.shape[1:])\n",
    "encoded1 = Conv2D(hidden_layer1, (3, 3),activation=activation_1,padding='same')(input_img)\n",
    "decoded1 = Conv2D(3, (3, 3), activation=decoder_activation, padding='same')(encoded1)\n",
    "autoencoder1 = Model(input_img, decoded1)\n",
    "autoencoder1.compile(optimizer='adam', loss=loss_)\n",
    "autoencoder1.summary()\n",
    "autoencoder1.fit(x_train, x_train, epochs=15, batch_size=128,validation_data=(x_test, x_test))\n",
    "autoencoder1.save('autoencoder_layer1.h5')\n",
    "###BUILD AUTOENCODER2\n",
    "encoded1 = autoencoder1.layers[1](autoencoder1.input)\n",
    "#AUTOENCODER2\n",
    "encoded2 = Conv2D(hidden_layer2,(3, 3), activation=activation_2, padding='same')(encoded1) \n",
    "decoded2 = Conv2D(hidden_layer1,(3, 3), activation=decoder_activation2,padding='same')(encoded2) \n",
    "#finish AUTOENCODER2\n",
    "decoded1 = autoencoder1.layers[-1](decoded2)\n",
    "autoencoder2 = Model(autoencoder1.input, decoded1) #all model\n",
    "#autoencoder1 set fixed\n",
    "autoencoder2.layers[1].trainable=False\n",
    "autoencoder2.layers[-1].trainable=False\n",
    "autoencoder2.compile(optimizer='adam', loss=loss_)\n",
    "autoencoder2.summary()\n",
    "autoencoder2.fit(x_train, x_train, epochs=10, batch_size=128,validation_data=(x_test, x_test))\n",
    "autoencoder2.save('autoencoder_layer2.h5')\n",
    "#FINE TUNNING\n",
    "model = Sequential()\n",
    "model.add(Conv2D(hidden_layer1,(3, 3),padding='same',activation=activation_1,input_shape=x_train.shape[1:]))\n",
    "model.layers[-1].set_weights(autoencoder1.layers[1].get_weights())\n",
    "model.add(Conv2D(hidden_layer2, (3, 3),padding='same',activation=activation_2))\n",
    "model.layers[-1].set_weights(autoencoder2.layers[2].get_weights())\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "...#rest of the model\n",
    "optimizer_ = keras.optimizers.SGD(lr=0.01,momentum=0.9)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optimizer_, metrics=['accuracy'])\n",
    "model.fit(x_train, y_train, batch_size=128,epochs=15,verbose=1, alidation_data=(x_test, y_test))\n",
    "```\n",
    "\n",
    "> d) Otra forma de hacer lo que se conoce como *transfer learning* es utilizar el conocimiento (los parámetros) aprendido por una red entrenada con millones de imágenes, y tomar estos parámetros como los pre entrenados. Para esto se utilizará el modelo VGG16 [7] proporcionado a través de la interfaz de keras. Visualice el modelo y sus 23 capas. Para esta instancia se utilizará todo lo aprendido por las capas convolucionales, es decir, se eliminan las capas densas del modelo y se agregan unas nuevas a ser entrenadas desde cero.\n",
    "```python\n",
    "from keras.applications import VGG16\n",
    "#LOAD PRETRAINED MODEL \n",
    "input_tensor=Input(shape=x_train.shape[1:])\n",
    "modelVGG = VGG16(weights='imagenet', include_top=False,input_tensor=input_tensor )\n",
    "features_train = modelVGG.predict(x_train)\n",
    "features_test = modelVGG.predict(x_test)\n",
    "modelVGG.summary()\n",
    "```\n",
    "\n",
    "> e) Entrene esta red agregando una capa densa de 1024 neuronas seguido de un dropout de 0.5, finalmente es necesario agregar la capa de clasificación para las 100 clases. Utilice la misma configuración del optimizador para que las comparaciones sean válidas. Entrene unicamente por 10 *epochs* ¿Qué sucede? Comente.\n",
    "```python\n",
    "model = Sequential()\n",
    "model.add(Flatten(input_shape=features_train.shape[1:]))\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "...#clasification\n",
    "model.compile(optimizer=optimizer_,loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit(features_train, y_train,epochs=epochs_, batch_size=128,verbose=1,validation_data=(features_test,y_test))\n",
    "```\n",
    "\n",
    "> f) Agregue una capa de normalización (*Batch Normalization* [8]) de las activaciones en las capas densas, esto es, restar por la media del batch y dividir por la desviación estándar. Vuelva a entrenar el modelo con la misma configuración pero ahora por **15 *epochs***. Comente lo observado y compare las curvas de convergencia con los modelos anteriores ¿Por qué esto mejora a lo presentado en e)? Realice los mismos gráficos que en a) a través del número de *epochs* y comente sobre el tiempo de ejecución de este entrenamiento.\n",
    "```python\n",
    "model = Sequential()\n",
    "model.add(Flatten(input_shape=features_train.shape[1:]))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.5))\n",
    "...\n",
    "```\n",
    "\n",
    "> g) Anteriormente se dejaron fijas las capas de convolución de VGG16, ahora experimente comentando sobre la convergencia y el tiempo de ejecución el entrenar la última tanda de convoluciones de VGG16, es decir, tome como punto inicial los pesos pre entrenados de esta red en *Imagenet* y entrenelos para este problema.\n",
    "```python\n",
    "#LOAD PRETRAINED MODEL \n",
    "input_tensor=Input(shape=x_train.shape[1:])\n",
    "modelVGG = VGG16(weights='imagenet', include_top=False,input_tensor=input_tensor )\n",
    "salida_vgg = modelVGG.get_layer('block4_pool').output_shape\n",
    "model = Sequential()\n",
    "model.add(Conv2D(512,(3, 3),input_shape=salida_vgg[1:],activation='relu',padding='same'))\n",
    "model.add(Conv2D(512,(3, 3),activation='relu',padding='same'))\n",
    "model.add(Conv2D(512,(3, 3),activation='relu',padding='same'))\n",
    "model.add(MaxPooling2D((2, 2),strides=(2,2)))    \n",
    "##dense section\n",
    "model.add(Flatten())\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(100, activation='softmax'))\n",
    "#delete last 4 layers of VGG16 and transfer the weight to new model\n",
    "modelVGG.layers.pop() #delete last maxpooling\n",
    "for i in np.arange(2,-1,-1):\n",
    "    last = modelVGG.layers.pop() #delete convolutional layers\n",
    "    model.layers[i].set_weights(last.get_weights())\n",
    "from keras.models import Model\n",
    "crop_modelVGG = Model(inputs=modelVGG.input, outputs=modelVGG.layers[-1].output)\n",
    "features_train = crop_modelVGG.predict(x_train)\n",
    "features_test = crop_modelVGG.predict(x_test)\n",
    "#train it\n",
    "model.compile(optimizer=optimizer_,loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit(features_train,y_train,epochs=15,batch_size=128,verbose=1,validation_data=(features_test,y_test))\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py3]",
   "language": "python",
   "name": "conda-env-py3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
